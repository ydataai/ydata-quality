{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YData Quality - DataQuality Tutorial\n",
    "Time-to-Value: 4 minutes\n",
    "\n",
    "This notebook provides a tutorial to run the `ydata_quality.DataQuality` main class that aggregates all the individual data quality engines, each focused on a main topic of data quality (e.g. duplicates, missing values).\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "1. Load dataset\n",
    "2. Distort dataset\n",
    "3. Instantiate the Data Quality engine\n",
    "4. Run the quality checks\n",
    "5. Assess the warnings\n",
    "6. (Extra) Detailed overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from ydata_quality import DataQuality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the example dataset\n",
    "We will use a dataset available from the statsmodels package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = sm.datasets.get_rdataset('Guerry', 'HistData').data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distort the original dataset\n",
    "Apply transformations to highlight the data quality functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def apply_quality_transformations(df: pd.DataFrame):\n",
    "    \"Force data quality issues to highlight functionality.\"\n",
    "    # Copy to guarantee the original is kept intact\n",
    "    df = df.copy()\n",
    "\n",
    "    # Duplicates\n",
    "    df = df.append(df[:20], ignore_index=True)\n",
    "    df[\"dept2\"] = df[\"dept\"]\n",
    "    return df\n",
    "\n",
    "df = apply_quality_transformations(df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the main engine\n",
    "The DataQuality class aggregates all the individual data quality engines, each focused on a main topic of data quality (e.g. duplicates, missing values). To create a DataQuality object, you provide:\n",
    "- df: target DataFrame, for which we will run the test suite\n",
    "- target (optional): target feature to be predicted in a supervised learning context\n",
    "- entities (optional): list of feature names for which checking duplicates after grouping-by is applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq = DataQuality(df=df, target='Pop1831')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Evaluation\n",
    "The easiest way to assess the data quality analysis is to run `.evaluate()` which returns a list of warnings for each quality check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENTITY DUPLICATES] There are no entities defined to run the analysis. Skipping the test.\n",
      "WARNING: Skipping test predict_missings due to failure during computation.\n",
      "[MISSING LABELS] No missing labels were found.\n",
      "[TEST NORMALITY] It was not possible to normalize the label values. See the warning message for additional context.\n"
     ]
    }
   ],
   "source": [
    "full_results = dq.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the status\n",
    "After running the data quality checks, you can check the warnings for each individual test. The warnings are suited by priority and have additional details that can provide better insights for Data Scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DUPLICATE COLUMNS] Found 1 columns with exactly the same feature values as other columns. (Priority 1: heavy impact expected)\n",
      "[EXACT DUPLICATES] Found 20 instances with exact duplicate feature values. (Priority 2: usage allowed, limited human intelligibility)\n",
      "[OUTLIER DETECTION] Found 2 potential outliers across the full dataset.                        \n",
      "\tA distance bigger than 3.0 standard deviations of intra-cluster distances to the respective centroids was used to define the potential outliers. (Priority 2: usage allowed, limited human intelligibility)\n",
      "[TEST NORMALITY] The label distribution failed to pass a normality test as-is and following a battery of transforms.                        \n",
      "\tIt is possible that the data originates from an exotic distribution, there is heavy outlier presence or it is multimodal.                        \n",
      "\tAddressing this issue might prove critical for regressor performance. (Priority 1: heavy impact expected)\n"
     ]
    }
   ],
   "source": [
    "dq.report()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdb8905eeefe08da097059bda365f0d7e393b9cc818106eee5be3ebd28cc5e41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10  ('.venv': venv)",
   "name": "pythonjvsc74a57bd0cdc2bce73c2a9ac283f602628cabf735dbe06c4ee87a7849fc5f3d1177c8f304"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "cdc2bce73c2a9ac283f602628cabf735dbe06c4ee87a7849fc5f3d1177c8f304"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}