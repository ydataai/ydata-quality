{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# YData Quality - DataQuality Tutorial\n",
    "Time-to-Value: 4 minutes\n",
    "\n",
    "This notebook provides a tutorial to run the `ydata_quality.DataQuality` main class that aggregates all the individual data quality engines, each focused on a main topic of data quality (e.g. duplicates, missing values).\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "1. Load dataset\n",
    "2. Distort dataset\n",
    "3. Instantiate the Data Quality engine\n",
    "4. Run the quality checks\n",
    "5. Assess the warnings\n",
    "6. (Extra) Detailed overview"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "from ydata_quality import DataQuality"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the example dataset\n",
    "We will use a transformed version of the \"Guerry\" dataset available from the statsmodels package."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('../datasets/transformed/guerry_histdata.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the main engine\n",
    "The DataQuality class aggregates all the individual data quality engines, each focused on a main topic of data quality (e.g. duplicates, missing values). To create a DataQuality object, you provide:\n",
    "- df: target DataFrame, for which we will run the test suite\n",
    "- target (optional): target feature to be predicted in a supervised learning context\n",
    "- entities (optional): list of feature names for which checking duplicates after grouping-by is applicable.\n",
    "- ed_extensions (optional): list of erroneous data values to append to the defaults."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "ED_EXTENSIONS = ['a_custom_EDV', 999999999, '!', '', 'UNKNOWN']\n",
    "SENSITIVE_FEATURES = ['Suicides', 'Crime_parents', 'Infanticide']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dq = DataQuality(df=df, label='Pop1831', ed_extensions=ED_EXTENSIONS, sensitive_features=SENSITIVE_FEATURES, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Full Evaluation\n",
    "The easiest way to assess the data quality analysis is to run `.evaluate()` which returns a list of warnings for each quality check. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "full_results = dq.evaluate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CRITICAL | Canceled Data Expectations engine execution due to dataset-expectation suite mismatch.\n",
      "\u001b[1mWarnings:\u001b[0m\n",
      "\tTOTAL: 7 warning(s)\n",
      "\t\u001b[1m\u001b[38;5;209mPriority 1\u001b[0m: 2 warning(s)\n",
      "\t\u001b[1m\u001b[38;5;11mPriority 2\u001b[0m: 5 warning(s)\n",
      "\n",
      "\u001b[38;5;209m\u001b[1mPriority 1\u001b[0m - \u001b[1mheavy impact expected\u001b[0m:\n",
      "\t\u001b[38;5;209m*\u001b[0m \u001b[1m[LABELS\u001b[0m - \u001b[4mTEST NORMALITY]\u001b[0m The label distribution failed to pass a normality test as-is and following a battery of transforms. It is possible that the data originates from an exotic distribution, there is heavy outlier presence or it is multimodal. Addressing this issue might prove critical for regressor performance.\n",
      "\t\u001b[38;5;209m*\u001b[0m \u001b[1m[DUPLICATES\u001b[0m - \u001b[4mDUPLICATE COLUMNS]\u001b[0m Found 1 columns with exactly the same feature values as other columns.\n",
      "\u001b[38;5;11m\u001b[1mPriority 2\u001b[0m - \u001b[1musage allowed, limited human intelligibility\u001b[0m:\n",
      "\t\u001b[38;5;11m*\u001b[0m \u001b[1m[DATA RELATIONS\u001b[0m - \u001b[4mHIGH COLLINEARITY - NUMERICAL]\u001b[0m Found 18 numerical variables with high Variance Inflation Factor (VIF>5.0). The variables listed in results are highly collinear with other variables in the dataset. These will make model explainability harder and potentially give way to issues like overfitting. Depending on your end goal you might want to remove the highest VIF variables.\n",
      "\t\u001b[38;5;11m*\u001b[0m \u001b[1m[DUPLICATES\u001b[0m - \u001b[4mEXACT DUPLICATES]\u001b[0m Found 20 instances with exact duplicate feature values.\n",
      "\t\u001b[38;5;11m*\u001b[0m \u001b[1m[DATA RELATIONS\u001b[0m - \u001b[4mHIGH COLLINEARITY - CATEGORICAL]\u001b[0m Found 3 categorical variables with significant collinearity (p-value < 0.05). The variables listed in results are highly collinear with other variables in the dataset and sorted descending according to propensity. These will make model explainability harder and potentially give way to issues like overfitting. Depending on your end goal you might want to remove variables following the provided order.\n",
      "\t\u001b[38;5;11m*\u001b[0m \u001b[1m[BIAS&FAIRNESS\u001b[0m - \u001b[4mPROXY IDENTIFICATION]\u001b[0m Found 5 feature pairs of correlation to sensitive attributes with values higher than defined threshold (0.5).\n",
      "\t\u001b[38;5;11m*\u001b[0m \u001b[1m[LABELS\u001b[0m - \u001b[4mOUTLIER DETECTION]\u001b[0m Found 2 potential outliers across the full dataset. A distance bigger than 3.0 standard deviations of intra-cluster distances to the respective centroids was used to define the potential outliers.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the status\n",
    "After running the data quality checks, you can check the warnings for each individual test. The warnings are suited by priority and have additional details that can provide better insights for Data Scientists."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Retrieve the warnings\n",
    "warnings = dq.get_warnings()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# With get_warnings you can also filter the warning list by specific conditions\n",
    "duplicate_quality_warnings = dq.get_warnings(category='Duplicates')\n",
    "priority_2_warnings = dq.get_warnings(priority=2)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdc2bce73c2a9ac283f602628cabf735dbe06c4ee87a7849fc5f3d1177c8f304"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "cdc2bce73c2a9ac283f602628cabf735dbe06c4ee87a7849fc5f3d1177c8f304"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}